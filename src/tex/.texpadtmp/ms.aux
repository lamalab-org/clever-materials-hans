\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@refcontext{none/global//global/global/global}
\abx@aux@cite{0}{hardtrecht2022patterns}
\abx@aux@segm{0}{0}{hardtrecht2022patterns}
\abx@aux@cite{0}{Lones2024}
\abx@aux@segm{0}{0}{Lones2024}
\abx@aux@cite{0}{Lapuschkin2019}
\abx@aux@segm{0}{0}{Lapuschkin2019}
\abx@aux@cite{0}{Brown2023}
\abx@aux@segm{0}{0}{Brown2023}
\abx@aux@cite{0}{Howard2021}
\abx@aux@segm{0}{0}{Howard2021}
\abx@aux@cite{0}{pooch2019trust}
\abx@aux@segm{0}{0}{pooch2019trust}
\abx@aux@cite{0}{xiao2020noise}
\abx@aux@segm{0}{0}{xiao2020noise}
\abx@aux@cite{0}{leash}
\abx@aux@segm{0}{0}{leash}
\abx@aux@cite{0}{shabih2026autonomous}
\abx@aux@segm{0}{0}{shabih2026autonomous}
\HyPL@Entry{0<</S/D>>}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {In machine learning, we often do not test competing hypotheses of how a model might obtain its answers.} Machine learning models in materials science are trained to map material (descriptors) to property predictions. Models have much flexibility in how they learn this map from data. Ideally, they discover robust and meaningful structure-property relationships that also generalize in new settings. This, however, is not guaranteed. Models might also exploit other patterns in the data as a shortcut to a prediction (\enquote {purple}). For instance, it might be easy for the model to spot what researchers produced a given material or in what journal it has been published. Based on those inferences, it might deduce property \enquote {guesses} (as the knowledge of the research group or the publication time can be correlated to the property). The model thus might learn to make good predictions for the wrong reasons. This is known as the \enquote {Clever Hans} effect. The scientific method asks us to test if such alternative patterns can explain good model performance. This is seldom done. In this work, I do it for a few case studies. }}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:clever_hans}{{1}{2}{\textbf {In machine learning, we often do not test competing hypotheses of how a model might obtain its answers.} Machine learning models in materials science are trained to map material (descriptors) to property predictions. Models have much flexibility in how they learn this map from data. Ideally, they discover robust and meaningful structure-property relationships that also generalize in new settings. This, however, is not guaranteed. Models might also exploit other patterns in the data as a shortcut to a prediction (\enquote {purple}). For instance, it might be easy for the model to spot what researchers produced a given material or in what journal it has been published. Based on those inferences, it might deduce property \enquote {guesses} (as the knowledge of the research group or the publication time can be correlated to the property). The model thus might learn to make good predictions for the wrong reasons. This is known as the \enquote {Clever Hans} effect. The scientific method asks us to test if such alternative patterns can explain good model performance. This is seldom done. In this work, I do it for a few case studies}{figure.caption.1}{}}
\newlabel{fig:clever_hans@cref}{{[figure][1][]1}{[1][2][]2}{}{}{}}
\abx@aux@cite{0}{Kalmutzki2018}
\abx@aux@segm{0}{0}{Kalmutzki2018}
\abx@aux@cite{0}{Nandy2022}
\abx@aux@segm{0}{0}{Nandy2022}
\abx@aux@cite{0}{Nandy2022}
\abx@aux@segm{0}{0}{Nandy2022}
\abx@aux@cite{0}{Nandy2021}
\abx@aux@segm{0}{0}{Nandy2021}
\abx@aux@cite{0}{Nandy2022}
\abx@aux@segm{0}{0}{Nandy2022}
\abx@aux@cite{0}{Nandy2022}
\abx@aux@segm{0}{0}{Nandy2022}
\abx@aux@cite{0}{Nandy2021}
\abx@aux@segm{0}{0}{Nandy2021}
\abx@aux@cite{0}{Nandy2021}
\abx@aux@segm{0}{0}{Nandy2021}
\@writefile{toc}{\contentsline {section}{\numberline {2}Results}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}MOF Thermal Stability}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}MOF Solvent Stability}{3}{subsection.2.2}\protected@file@percent }
\abx@aux@cite{0}{CorreaBaena2017}
\abx@aux@segm{0}{0}{CorreaBaena2017}
\abx@aux@cite{0}{Jacobsson2021}
\abx@aux@segm{0}{0}{Jacobsson2021}
\abx@aux@cite{0}{Jacobsson2021}
\abx@aux@segm{0}{0}{Jacobsson2021}
\abx@aux@cite{0}{shabih2026autonomous}
\abx@aux@segm{0}{0}{shabih2026autonomous}
\abx@aux@cite{0}{shabih2026autonomous}
\abx@aux@segm{0}{0}{shabih2026autonomous}
\abx@aux@cite{0}{SchillingWilhelmi2025}
\abx@aux@segm{0}{0}{SchillingWilhelmi2025}
\abx@aux@cite{0}{Huang2020}
\abx@aux@segm{0}{0}{Huang2020}
\abx@aux@cite{0}{Huang2020}
\abx@aux@segm{0}{0}{Huang2020}
\abx@aux@cite{0}{Liu2018}
\abx@aux@segm{0}{0}{Liu2018}
\abx@aux@cite{0}{Huang2024}
\abx@aux@segm{0}{0}{Huang2024}
\abx@aux@cite{0}{Huang2024}
\abx@aux@segm{0}{0}{Huang2024}
\abx@aux@cite{0}{Swain2016}
\abx@aux@segm{0}{0}{Swain2016}
\abx@aux@cite{0}{Mavrai2021}
\abx@aux@segm{0}{0}{Mavrai2021}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {For the classification task of membership in the top-10\% of thermally stable MOFs, one can be fooled (by Clever Hans effects).} The model can predict the bibliographic information with high accuracy. \textbf  {a} The model predicts the authors of the associated paper with high accuracy, much better than a random baseline. \textbf  {b} This also holds for predicting in which journal the entry was published or the year in which the paper was published (\textbf  {c}). Using the predicted bibliographic information, a model can also predict with high accuracy if the MOF belongs to the top-10\% thermally stable ones. However, one needs to highlight that the effect is smaller --- or not even there --- if analyzed under a different metric or for a regression setting. The dummy baseline for classification is a stratified random sampling (using the empirical probabilities from the training dataset) and the mean prediction for the regression case.}}{4}{figure.caption.2}\protected@file@percent }
\newlabel{fig:mof_thermal_stability}{{2}{4}{\textbf {For the classification task of membership in the top-10\% of thermally stable MOFs, one can be fooled (by Clever Hans effects).} The model can predict the bibliographic information with high accuracy. \textbf {a} The model predicts the authors of the associated paper with high accuracy, much better than a random baseline. \textbf {b} This also holds for predicting in which journal the entry was published or the year in which the paper was published (\textbf {c}). Using the predicted bibliographic information, a model can also predict with high accuracy if the MOF belongs to the top-10\% thermally stable ones. However, one needs to highlight that the effect is smaller --- or not even there --- if analyzed under a different metric or for a regression setting. The dummy baseline for classification is a stratified random sampling (using the empirical probabilities from the training dataset) and the mean prediction for the regression case}{figure.caption.2}{}}
\newlabel{fig:mof_thermal_stability@cref}{{[figure][2][]2}{[1][3][]4}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:mof_solvent_stability}{{3}{4}{\relax }{figure.caption.3}{}}
\newlabel{fig:mof_solvent_stability@cref}{{[figure][3][]3}{[1][3][]4}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Perovskite Solar Cell Efficiency}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Battery Capacity}{4}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax }}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:perovskite_pce_classification}{{4}{4}{\relax }{figure.caption.4}{}}
\newlabel{fig:perovskite_pce_classification@cref}{{[figure][4][]4}{[1][4][]4}{}{}{}}
\abx@aux@cite{0}{Moosavi2020}
\abx@aux@segm{0}{0}{Moosavi2020}
\abx@aux@cite{0}{Saal2020}
\abx@aux@segm{0}{0}{Saal2020}
\abx@aux@cite{0}{Gubernatis2018}
\abx@aux@segm{0}{0}{Gubernatis2018}
\abx@aux@cite{0}{Platt1964}
\abx@aux@segm{0}{0}{Platt1964}
\abx@aux@cite{0}{popper2005logic}
\abx@aux@segm{0}{0}{popper2005logic}
\abx@aux@cite{0}{Chamberlin1965}
\abx@aux@segm{0}{0}{Chamberlin1965}
\abx@aux@cite{0}{Chuang2018}
\abx@aux@segm{0}{0}{Chuang2018}
\abx@aux@cite{0}{Zhou2025}
\abx@aux@segm{0}{0}{Zhou2025}
\abx@aux@cite{0}{Jones2024}
\abx@aux@segm{0}{0}{Jones2024}
\abx@aux@cite{0}{Ramos2025}
\abx@aux@segm{0}{0}{Ramos2025}
\abx@aux@cite{0}{alampara2025general}
\abx@aux@segm{0}{0}{alampara2025general}
\abx@aux@cite{0}{Krishnan2025}
\abx@aux@segm{0}{0}{Krishnan2025}
\abx@aux@cite{0}{Nielsen2020-rr}
\abx@aux@segm{0}{0}{Nielsen2020-rr}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Battery capacity}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:battery_capacity}{{5}{5}{Battery capacity}{figure.caption.5}{}}
\newlabel{fig:battery_capacity@cref}{{[figure][5][]5}{[1][4][]5}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}TADF Emitter Properties}{5}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Discussion}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Toward Robust Materials Data Infrastructure}{5}{subsection.3.1}\protected@file@percent }
\abx@aux@cite{0}{Jia2019}
\abx@aux@segm{0}{0}{Jia2019}
\abx@aux@cite{0}{goldman2024statistical}
\abx@aux@segm{0}{0}{goldman2024statistical}
\abx@aux@cite{0}{Alampara2025}
\abx@aux@segm{0}{0}{Alampara2025}
\abx@aux@cite{0}{sheridan2013time}
\abx@aux@segm{0}{0}{sheridan2013time}
\abx@aux@cite{0}{Landrum2023}
\abx@aux@segm{0}{0}{Landrum2023}
\abx@aux@cite{0}{Durdy2022}
\abx@aux@segm{0}{0}{Durdy2022}
\abx@aux@cite{0}{Meredig2018}
\abx@aux@segm{0}{0}{Meredig2018}
\abx@aux@cite{0}{guo2024scaffold}
\abx@aux@segm{0}{0}{guo2024scaffold}
\abx@aux@cite{0}{Jablonka2023}
\abx@aux@segm{0}{0}{Jablonka2023}
\abx@aux@cite{0}{kunchapu2025polymetrix}
\abx@aux@segm{0}{0}{kunchapu2025polymetrix}
\abx@aux@cite{0}{Moult2005}
\abx@aux@segm{0}{0}{Moult2005}
\abx@aux@cite{0}{Tetko2024}
\abx@aux@segm{0}{0}{Tetko2024}
\abx@aux@cite{0}{Llinas2019}
\abx@aux@segm{0}{0}{Llinas2019}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions}{6}{section.4}\protected@file@percent }
\abx@aux@cite{0}{lightgbm}
\abx@aux@segm{0}{0}{lightgbm}
\@writefile{toc}{\contentsline {section}{\numberline {5}Methods}{7}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Clever Hans Analysis Framework}{7}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Model Architecture and Training}{7}{subsection.5.2}\protected@file@percent }
\abx@aux@cite{0}{Huang2020}
\abx@aux@segm{0}{0}{Huang2020}
\abx@aux@cite{0}{Huang2020}
\abx@aux@segm{0}{0}{Huang2020}
\abx@aux@cite{0}{shabih2026autonomous}
\abx@aux@segm{0}{0}{shabih2026autonomous}
\abx@aux@cite{0}{shabih2026autonomous}
\abx@aux@segm{0}{0}{shabih2026autonomous}
\abx@aux@cite{0}{Jacobsson2021}
\abx@aux@segm{0}{0}{Jacobsson2021}
\abx@aux@cite{0}{Jacobsson2021}
\abx@aux@segm{0}{0}{Jacobsson2021}
\abx@aux@cite{0}{Nandy2022}
\abx@aux@segm{0}{0}{Nandy2022}
\abx@aux@cite{0}{Nandy2022}
\abx@aux@segm{0}{0}{Nandy2022}
\abx@aux@cite{0}{Moosavi2020}
\abx@aux@segm{0}{0}{Moosavi2020}
\abx@aux@cite{0}{Huang2024}
\abx@aux@segm{0}{0}{Huang2024}
\abx@aux@cite{0}{Huang2024}
\abx@aux@segm{0}{0}{Huang2024}
\abx@aux@cite{0}{Weininger1988}
\abx@aux@segm{0}{0}{Weininger1988}
\abx@aux@cite{0}{rdkit}
\abx@aux@segm{0}{0}{rdkit}
\abx@aux@cite{0}{matminer}
\abx@aux@segm{0}{0}{matminer}
\abx@aux@cite{0}{ward2016general}
\abx@aux@segm{0}{0}{ward2016general}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Datasets and Feature Engineering}{8}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Battery Dataset}{8}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Perovskite Dataset}{8}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}MOF Datasets}{8}{subsubsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}TADF Dataset}{8}{subsubsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Chemical Descriptor Generation}{8}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Molecular Descriptors from SMILES}{8}{subsubsection.5.4.1}\protected@file@percent }
\abx@aux@cite{0}{meredig2014combinatorial}
\abx@aux@segm{0}{0}{meredig2014combinatorial}
\abx@aux@cite{0}{pymatgen}
\abx@aux@segm{0}{0}{pymatgen}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}Composition Descriptors}{9}{subsubsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.3}Feature Processing}{9}{subsubsection.5.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Meta-Information Extraction}{9}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Data Processing}{9}{subsection.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Detailed Results}{16}{appendix.A}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{5DB7D1898EAF56762D69B8491563A9BB}
\abx@aux@defaultrefcontext{0}{hardtrecht2022patterns}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Lones2024}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Lapuschkin2019}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Brown2023}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Howard2021}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{pooch2019trust}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{xiao2020noise}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{leash}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{shabih2026autonomous}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Kalmutzki2018}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Nandy2022}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Nandy2021}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{CorreaBaena2017}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Jacobsson2021}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{SchillingWilhelmi2025}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Huang2020}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Liu2018}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Huang2024}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Swain2016}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Mavrai2021}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Moosavi2020}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Saal2020}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Gubernatis2018}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Platt1964}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{popper2005logic}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Chamberlin1965}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Chuang2018}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Zhou2025}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Jones2024}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Ramos2025}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{alampara2025general}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Krishnan2025}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Nielsen2020-rr}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Jia2019}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{goldman2024statistical}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Alampara2025}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{sheridan2013time}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Landrum2023}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Durdy2022}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Meredig2018}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{guo2024scaffold}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Jablonka2023}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{kunchapu2025polymetrix}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Moult2005}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Tetko2024}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Llinas2019}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{lightgbm}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{Weininger1988}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{rdkit}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{matminer}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ward2016general}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{meredig2014combinatorial}{none/global//global/global/global}
\abx@aux@defaultrefcontext{0}{pymatgen}{none/global//global/global/global}
\gdef \@abspage@last{16}
